2023-03-07  dyuret  <dyuret@login03.kuacc.ku.edu.tr>

	* MLP-Summary:
	trn		abcval	abcval1	dval	dval1
	---		------	-------	----	-----
	ABCD-32x32	.9577	.9604	.8935	.9070
	ABCD-1x32	.5306	.9890	.4319	.9199
	ABCD-32x4	.9113	.8418	.8810	.8299
	ABCD-32x1	.8711	.7939	.8378	.7893
	ABC-32x32	.6136	.5832	.5854	.5658
	ABC-1x32	.3329	.7121	.2848	.6469
	ABC-32x4	.6403	.5915	.6159	.5697
	ABC-32x1	.6380	.6109	.6060	.5687
	D-32x32		.8968	.8905	.8827	.8892
	D-1x32   	.5507	.9154	.4623	.9426
	D-32x4   	.8969	.8151	.8817	.8051
	D-32x1   	.8764	.7884	.8667	.7784

	Notes:
	- ABC-32x4 means 32 instances per episode from its last 32 frames, each instance has a 4 frame context.
	- abcval evaluates accuracy on the last 32 frames of each episode, abcval1 evaluates only on the last frame.
	- ABCD and ABC used earlystop based on abcval, D used earlystop based on dval.
	- D contains training instances only from D, ABC from A,B,C and ABCD is a union of the two training sets.
	- The validation sets contain instances only from D (disjoint from training).
	- abcval and abcdval has the same language annotations, dval has different language annotations.


2023-03-06  dyuret  <dyuret@login03.kuacc.ku.edu.tr>

	* TODO:
	- Train a 32x32 model.
	- Print out confusion matrix.
	- Emphasize the differences using a smart scaled difference functions (careful about episode boundaries and 2pi angle differences).
	- try tensorboard
	- try rnn

	* +: See how episode-based (ABCD) model does on an individual frame basis.
	>>> for i in [1,2,4,8,16,32]:
	...   d = ld.calvindataset("../data/ABC-validation", instances_per_episode=i, context_length=32)
	...   print('instances per episode = ', i)
	...   tr.validate(m1, DataLoader(d, batch_size=32))
	last-1-frame:   [{'val_loss': 0.046598080545663834, 'val_acc': 0.9889604449272156}]
	last-2-frames:  [{'val_loss': 0.04988009110093117,  'val_acc': 0.9885004758834839}]
	last-4-frames:  [{'val_loss': 0.0645752102136612,   'val_acc': 0.9855105876922607}]
	last-8-frames:  [{'val_loss': 0.14425814151763916,  'val_acc': 0.9643514156341553}]
	last-16-frames: [{'val_loss': 0.7874042987823486,   'val_acc': 0.8522309064865112}]
	last-32-frames: [{'val_loss': 4.200976848602295,    'val_acc': 0.5305888056755066}]
	last-32-frames: [{'val_loss': 0.4216434359550476,   'val_acc': 0.871147632598877}]   (32x1-frame-model)
	last-32-frames: [{'val_loss': 0.24731987714767456,  'val_acc': 0.9218031167984009}]  (32x4-frame-model)

	* +: See how frame-based (ABCD) model does on the last frame of each episode.
	>>> d = ld.calvindataset("../data/ABC-validation", instances_per_episode=1, context_length=(4|1))
	32x1-frame-model: [{'val_loss': 0.6967383623123169, 'val_acc': 0.7939282655715942}]  (on last frame)
	32x1-frame-model: [{'val_loss': 0.4216434359550476, 'val_acc': 0.871147632598877}]   (on all frames)
	32x4-frame-model: [{'val_loss': 0.6505945324897766, 'val_acc': 0.8012879490852356}]  (on last frame)
	32x4-frame-model: [{'val_loss': 0.2473198771476745, 'val_acc': 0.9218031167984009}]  (on all frames)
	32x32-frame-model:
	32x32-frame-model:

	* +: See what per-annotation accuracy is using majority voting of 32x1-frame or 32x4-frame models.


2023-03-05  dyuret  <dyuret@login03.kuacc.ku.edu.tr>

	* === MLP-Experiments-1x32frame: context_length=32, instances_per_episode=1

	* ABCD-1x32: wandb/run-20230305_224324-fqm3f8nl: (y1zidphb:dark-sky-84)
	- Can get 98% val acc with (using last 32 frames and all 73 features):
	- Note the large difference between abcval and dval (same data different annotations).
	abcdtrn = ld.calvindataset("../data/ABCD-training", instances_per_episode=1, context_length=32)
	abcdval = ld.calvindataset("../data/ABCD-validation", instances_per_episode=1, context_length=32))
	mlp.train(abcdtrn, abcdval, max_steps=150000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	tr = pl.Trainer(accelerator='gpu', devices=1, max_epochs=1)
	m1 = mlp.LitMLP.load_from_checkpoint('mlp_project/y1zidphb/checkpoints/epoch=180-step=129958.ckpt')
	tr.validate(m1, DataLoader(abcval, batch_size=32)) #=> [{'val_loss': 0.046598080545663834, 'val_acc': 0.9889604449272156}]
	tr.validate(m1, DataLoader(dval, batch_size=32))   #=> [{'val_loss': 0.4002395272254944, 'val_acc': 0.919881284236908}]

	* ABC-1x32: wandb/run-20230306_001846-3xaj8o6q: (e95afymd:drawn-wood-83)
	- Only able to get to %70 even with strong regularization:
	abctrn = ld.calvindataset("../data/ABC-training", instances_per_episode=1, context_length=32)
	abcval = ld.calvindataset("../data/ABC-validation", instances_per_episode=1, context_length=32)
	mlp.train(abctrn, abcval, max_steps=150000, batch_size=32, lr=0.0001, dropout=0.7, weight_decay=0.2, hidden=[512,512])
	m2 = mlp.LitMLP.load_from_checkpoint('mlp_project/e95afymd/checkpoints/epoch=77-step=43602.ckpt')
	tr.validate(m2, DataLoader(abcval, batch_size=32)) #=> [{'val_loss': 0.6437634825706482, 'val_acc': 0.712051510810852}]
	tr.validate(m2, DataLoader(dval, batch_size=32))   #=> [{'val_loss': 1.0606377124786377, 'val_acc': 0.6468842625617981}]

	* D-1x32: wandb/run-20230306_001635-p06ygu9d: (0xftsmbg:eternal-grass-82)
	- Pretty much all experiments converge to 93% for a range of regularizations.
	ABCD does significantly better on the same validation set.
	But D language annotations are different! And this time the order is reversed? Cooked val set for D-training?
	dtrn = ld.calvindataset("../data/ABC-training", instances_per_episode=1, context_length=32)
	dval = ld.calvindataset("../data/ABC-validation", instances_per_episode=1, context_length=32)
	mlp.train(dtrn, dval, max_steps=150000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	m3 = mlp.LitMLP.load_from_checkpoint('mlp_project/0xftsmbg/checkpoints/epoch=927-step=149408.ckpt')
	tr.validate(m3, DataLoader(abcval, batch_size=32)) #=> [{'val_loss': 0.3091912567615509, 'val_acc': 0.9153633713722229}]
	tr.validate(m3, DataLoader(dval, batch_size=32))   #=> [{'val_loss': 0.25575390458106995, 'val_acc': 0.9426310658454895}]


	* === MLP-Experiments-32x1-frame: context_length=1, instances_per_episode=32
	tr = pl.Trainer(accelerator='gpu', devices=1, max_epochs=1)

	* ABCD-32x1:
	abcdtrn = ld.calvindataset("../data/ABCD-training", instances_per_episode=32, context_length=1)
	abcdval = ld.calvindataset("../data/ABCD-validation", instances_per_episode=32, context_length=1)
	dval = ld.calvindataset1("../data/D-validation")
	mlp.train(abcdtrn, abcdval, max_steps=150000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	m1 = mlp.LitMLP.load_from_checkpoint('mlp_project/iyyed7m1/checkpoints/epoch=5-step=137796.ckpt')
	tr.validate(m1, DataLoader(abcdval, batch_size=32)) #=> [{'val_loss': 0.4216434359550476, 'val_acc': 0.871147632598877}]
	tr.validate(m1, DataLoader(dval, batch_size=32))    #=> [{'val_loss': 0.6235239505767822, 'val_acc': 0.8378152847290039}]

	* ABC-32x1:
	abctrn = ld.calvindataset("../data/ABC-training", instances_per_episode=32, context_length=1)
	abcval = ld.calvindataset("../data/ABC-validation", instances_per_episode=32, context_length=1)
	mlp.train(abctrn, abcval, max_steps=150000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	m2 = mlp.LitMLP.load_from_checkpoint('mlp_project/ondcx26m/checkpoints/epoch=5-step=107220.ckpt')
	tr.validate(m2, DataLoader(abcval, batch_size=32)) #=> [{'val_loss': 0.9127740859985352, 'val_acc': 0.6380232572555542}]
	tr.validate(m2, DataLoader(dval, batch_size=32))   #=> [{'val_loss': 1.1524760723114014, 'val_acc': 0.6060212850570679}]

	* D-32x1:
	dtrn = ld.calvindataset("../data/D-training", instances_per_episode=32, context_length=1)
	dval = ld.calvindataset("../data/D-validation", instances_per_episode=32, context_length=1)
	mlp.train(dtrn, dval, max_steps=150000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	m3 = mlp.LitMLP.load_from_checkpoint('mlp_project/ltfpotls/checkpoints/epoch=27-step=143472.ckpt')
	tr.validate(m3, DataLoader(abcval, batch_size=32)) #=> [{'val_loss': 0.38017138838768005, 'val_acc': 0.8763511776924133}]
	tr.validate(m3, DataLoader(dval, batch_size=32))   #=> [{'val_loss': 0.4305930435657501,  'val_acc': 0.8666542768478394}]


	* === MLP-Experiments-32x4-frame: context_length=4, instances_per_episode=32
	tr = pl.Trainer(accelerator='gpu', devices=1, max_epochs=1)

	* ABCD-32x4:
	abcdtrn = ld.calvindataset("../data/ABCD-training", instances_per_episode=32, context_length=4)
	abcdval = ld.calvindataset("../data/ABCD-validation", instances_per_episode=32, context_length=4)
	dval = ld.calvindataset("../data/D-validation", instances_per_episode=32, context_length=4)
	mlp.train(abcdtrn, abcdval, max_steps=150000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	m1 = mlp.LitMLP.load_from_checkpoint('mlp_project/dv9032kv/checkpoints/epoch=5-step=137796.ckpt')
	tr.validate(m1, DataLoader(abcdval, batch_size=32)) #=> [{'val_loss': 0.2637326419353485, 'val_acc': 0.9113097786903381}]
	tr.validate(m1, DataLoader(dval, batch_size=32))    #=> [{'val_loss': 0.4974829852581024, 'val_acc': 0.8810274600982666}]

	* ABC-32x4:
	abctrn = ld.calvindataset("../data/ABC-training", instances_per_episode=32, context_length=4)
	abcval = ld.calvindataset("../data/ABC-validation", instances_per_episode=32, context_length=4)
	mlp.train(abctrn, abcval, max_steps=150000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	m2 = mlp.LitMLP.load_from_checkpoint('mlp_project/0heo6gfj/checkpoints/epoch=2-step=53610.ckpt')
	tr.validate(m2, DataLoader(abcval, batch_size=32)) #=> [{'val_loss': 0.9169828295707703, 'val_acc': 0.6402943730354309}]
	tr.validate(m2, DataLoader(dval, batch_size=32))   #=> [{'val_loss': 1.178528904914856, 'val_acc': 0.6159433722496033}]

	* D-32x4:
	dtrn = ld.calvindataset("../data/D-training", instances_per_episode=32, context_length=4)
	dval = ld.calvindataset("../data/D-validation", instances_per_episode=32, context_length=4)
	mlp.train(dtrn, dval, max_steps=150000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	m3 = mlp.LitMLP.load_from_checkpoint('mlp_project/w29sr8tr/checkpoints/epoch=23-step=122976.ckpt')
	tr.validate(m3, DataLoader(abcval, batch_size=32)) #=> [{'val_loss': 0.31888464093208313, 'val_acc': 0.8968778848648071}]
	tr.validate(m3, DataLoader(dval, batch_size=32))   #=> [{'val_loss': 0.38751137256622314, 'val_acc': 0.8817383646965027}]


	* === MLP-Experiments-32x32-frame: context_length=32, instances_per_episode=32
	tr = pl.Trainer(accelerator='gpu', devices=1, max_epochs=1)
	dval = ld.calvindataset("../data/D-validation", instances_per_episode=32, context_length=32)
	dval1 = ld.calvindataset("../data/D-validation", instances_per_episode=1, context_length=32)
	abcval = ld.calvindataset("../data/ABC-validation", instances_per_episode=32, context_length=32)
	abcval1 = ld.calvindataset("../data/ABC-validation", instances_per_episode=1, context_length=32)

	* ABCD-32x32:
	abcdtrn = ld.calvindataset("../data/ABCD-training", instances_per_episode=32, context_length=32)
	mlp.train(abcdtrn, abcval, max_steps=1500000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	m1 = mlp.LitMLP.load_from_checkpoint('mlp_project/i7t7yfv6/checkpoints/epoch=16-step=390422.ckpt')
	tr.validate(m1, DataLoader(abcval, batch_size=32))  #=> [{'val_loss': 0.12283673137426376, 'val_acc': 0.9576817154884338}]
	tr.validate(m1, DataLoader(abcval1, batch_size=32)) #=> [{'val_loss': 0.1442822366952896, 'val_acc': 0.9604415893554688}]
	tr.validate(m1, DataLoader(dval, batch_size=32))    #=> [{'val_loss': 0.5026547908782959, 'val_acc': 0.8935151100158691}]
	tr.validate(m1, DataLoader(dval1, batch_size=32))   #=> [{'val_loss': 0.3591073453426361, 'val_acc': 0.9070227742195129}]

	* ABC-32x32: this is too low, more regularization needed
	abctrn = ld.calvindataset("../data/ABC-training", instances_per_episode=32, context_length=32)
	mlp.train(abctrn, abcval, max_steps=1500000, batch_size=32, lr=0.0001, dropout=0.75, weight_decay=0.25, hidden=[512,512])
	m2 = mlp.LitMLP.load_from_checkpoint('mlp_project/0dhghbx7/checkpoints/epoch=5-step=107220.ckpt')
	tr.validate(m2, DataLoader(abcval, batch_size=32))  #=> [{'val_loss': 0.9245778322219849, 'val_acc': 0.6136441826820374}]
	tr.validate(m2, DataLoader(abcval1, batch_size=32)) #=> [{'val_loss': 0.9777761101722717, 'val_acc': 0.5832566618919373}]
	tr.validate(m2, DataLoader(dval, batch_size=32))    #=> [{'val_loss': 1.2631582021713257, 'val_acc': 0.5854042768478394}]
	tr.validate(m2, DataLoader(dval1, batch_size=32))   #=> [{'val_loss': 1.1301568746566772, 'val_acc': 0.5657764673233032}]

	* D-32x32:
	dtrn = ld.calvindataset("../data/D-training", instances_per_episode=32, context_length=32)
	mlp.train(dtrn, dval, max_steps=1500000, batch_size=32, lr=0.0001, dropout=0.5, weight_decay=0.1, hidden=[512,512])
	m3 = mlp.LitMLP.load_from_checkpoint('mlp_project/bv1t44ac/checkpoints/epoch=41-step=215208.ckpt')
	tr.validate(m3, DataLoader(abcval, batch_size=32))  #=> [{'val_loss': 0.3558889627456665, 'val_acc': 0.8967629075050354}]
	tr.validate(m3, DataLoader(abcval1, batch_size=32)) #=> [{'val_loss': 0.3719893097877502, 'val_acc': 0.8905243873596191}]
	tr.validate(m3, DataLoader(dval, batch_size=32))    #=> [{'val_loss': 0.3902618885040283, 'val_acc': 0.8826656937599182}]
	tr.validate(m3, DataLoader(dval1, batch_size=32))   #=> [{'val_loss': 0.4161476790904999, 'val_acc': 0.8892185688018799}]


	* bugs:
	+ the validation results do not match when reload from checkpoint!
	We need to call m.eval() before accuracy. Call m.train() again to activate dropout etc.
	+ the validation sets of D and ABC are different (same data different language. ABC=ABCD)
	Reporting both
	+ wandb: cannot see max validation accuracy!
	pytorch lightning: checkpoint model at best val: https://pytorch-lightning.readthedocs.io/en/stable/common/checkpointing_intermediate.html
	use checkpoint_callback = ModelCheckpoint(monitor = "val_acc", mode = 'max')
	pl.Trainer(..., callbacks=[checkpoint_callback], ...)


	* hyperparameters:
	>>> a = torch.load('mlp_project/v3vfpaws/checkpoints/epoch=178-step=100000.ckpt')
	>>> a["hyper_parameters"]
	{'sizes': (2336, 512, 512, 34), 'lr': 0.0001, 'weight_decay': 0.1, 'dropout': 0.6}


2023-03-04  dyuret  <dyuret@login03.kuacc.ku.edu.tr>

	* mlp:
	+ 512 hidden 0.5 dropout gives 82% validation accuracy on D for single frame using all features.
	+ Using 2 or 3 frames only increase this less than 1%.
	+ Visualize the predictions to see what is going on.

	* system:
	+ error in process filter: No such directory found via CDPATH environment variable (emacs terminal with srun)
	  fixed disabling term-command-hook.

	* pl:
	+ forward vs predict_step: do we need both? forward is needed for predict.
	+ wandb init: can we log every run? currently starting python every time: need to call wandb.finish() at the end of experiment.


2023-03-02  dyuret  <dyuret@login03.kuacc.ku.edu.tr>

	* wandb: Emre Can notes:
	Accuracy Metric code-line: https://github.com/emrecanacikgoz/robot-language/blob/2520cef611b115eb62938dc8859be0738f0a4946/blind_robot/models/mlp.py#L82
	training epoch ending function: https://github.com/emrecanacikgoz/robot-language/blob/2520cef611b115eb62938dc8859be0738f0a4946/blind_robot/models/mlp.py#L88
	my wandb logger: https://github.com/emrecanacikgoz/robot-language/blob/2520cef611b115eb62938dc8859be0738f0a4946/main.py#L93
	project argumanı yeni proje açıyor hocam
	name argumanı ilgili projenin içindeki run adı
	aynı proje için several run yapıcaksanız name'i değiştirebilirsiniz

	* TODO:
	- load checkpoint
	+ measure val/trn loss
	+ measure val/trn acc
	- tensorboard
	+ wandb: when do you get a new run?
	+ visualize training curves
	+ normalization
	x overfitting: usual methods did not work, try feature selection, try delta of scene coordinates, delta of robot obs, lower frame rate, multiple frames.


2023-02-23  dyuret  <dyuret@login03.kuacc.ku.edu.tr>

	* TODO:
	- validate rel_actions formula
	- extract tactile pixels
	- see if controller coordinates are in the simulator: https://github.com/mees/calvin_env
	- try mlp on action classification with different inputs

2023-02-22  dyuret  <dyuret@login02.kuacc.ku.edu.tr>

	* controller-coordinates: door, drawer, button, switch.


2023-02-19  Deniz Yuret  <dyuret@WS001>

	* scene_info.npy:
	# | debug/training | {'calvin_scene_D': [358482, 361252]} |
	# | debug/validation | {'calvin_scene_D': [553567, 555241]} |
	# | D/training | {'calvin_scene_A': [0, 611098]} |
	# | D/validation | . |
	# | ABC/training | {'calvin_scene_B': [0, 598909], 'calvin_scene_C': [598910, 1191338], 'calvin_scene_A': [1191339, 1795044]} |
	# | ABC/validation | . |
	# | ABCD/training | {'calvin_scene_A': [1802438, 2406143], 'calvin_scene_B': [611099, 1210008], 'calvin_scene_C': [1210009, 1802437], 'calvin_scene_D': [0, 611098]} |
	# | ABCD/validation | . |


	* TODO:
	+ write intervals.py to check intervals: done, several off-by-one errors in ABCD/training (frames common with validation).
	+ check overlaps see if identical: all identical but renumbered.
	+ check visual difference in A vs D: B is lightest, A is darkest, C and D similar with C having a straight pattern, D a bit lighter.
	+ see if ep_start_end is consistent with frame diffs
	+ improved visualizer to see what number is what
